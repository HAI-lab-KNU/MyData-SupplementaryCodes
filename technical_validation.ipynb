{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLVtPgH8rfw0"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9g6zJ19r0gs"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0Z--TR8R_12C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH_DATA = './Dataset'\n",
    "sensor_data = ['UserInfo.csv', 'Service.csv', 'ContextualFactor.csv', 'Interruptibility.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbFFIwXfG-NX"
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YY8eN6XlYKpq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZh9HiKnHNUE"
   },
   "source": [
    "\n",
    "# Load the Dataset into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oatjHY6UI2fS"
   },
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    filename: pd.read_csv(os.path.join(PATH_DATA, filename)).reset_index(drop=True)\n",
    "    for filename in sensor_data\n",
    "}\n",
    "dfService = dataframes['Service.csv']\n",
    "dfContextualFactor = dataframes['ContextualFactor.csv']\n",
    "dfUserInfo = dataframes['UserInfo.csv']\n",
    "dfInterruptibility = dataframes['Interruptibility.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXvLBvF1tF12"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nSFuapG9u9HX"
   },
   "outputs": [],
   "source": [
    "# Select specific columns from dfContextualFactor, dfService, and dfUserInfo DataFrames\n",
    "# Combine relevant columns to create a unified dataset\n",
    "dfContextualFactor_selected_columns=dfContextualFactor[['uid','sid','activity1','activity2','activity3','userLocation','userPosition',]]\n",
    "dfService_selected_columns=dfService[['weekOfExperiment','dayOfWeek','startTime', 'activityInquiry','availabilityInquiry','speechShadowing1','speechShadowing2','speechShadowing3','speechShadowing4','speechShadowing5','continue-to-nextInquiry1','continue-to-nextInquiry2','continue-to-nextInquiry3','continue-to-nextInquiry4','endTime','endType']]\n",
    "dfInterruptibility_selected_columns=dfInterruptibility[['SHORT_INTERACTION_interruptibility', 'LONG_INTERACTION_interruptibility']]\n",
    "\n",
    "## Create binary columns for interaction types\n",
    "## SHORT_INTERACTION: True if availabilityInquiry is not NaN\n",
    "# dfCombinedAll['SHORT_INTERACTION_interruptibility'] = dfCombinedAll['availabilityInquiry'].notna()\n",
    "## LONG_INTERACTION: True if continue-to-nextInquiry1 is not NaN\n",
    "# dfCombinedAll['LONG_INTERACTION_interruptibility'] = dfCombinedAll['continue-to-nextInquiry1'].notna()\n",
    "\n",
    "# ! For those who want to redefine LONG_INTERACTION with thresholds longer than 3 minutes,\n",
    "# you can use the following columns:\n",
    "# 5 minutes  => use continue-to-nextInquiry2\n",
    "# 7 minutes  => use continue-to-nextInquiry3\n",
    "# 9 minutes  => use continue-to-nextInquiry4\n",
    "\n",
    "\n",
    "dfCombinedAll=pd.concat([dfContextualFactor_selected_columns, dfService_selected_columns,dfInterruptibility_selected_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "J-7MyCMpNEKf"
   },
   "outputs": [],
   "source": [
    "# Concatenate and merge the all columns from dfUserInfo (dfUserInfo.csv)\n",
    "dfUserInfo_selected_columns = dfUserInfo[['uid', 'homeType', 'speakerLocation', 'speakerPosition']]\n",
    "dfCombinedAll = pd.merge(dfCombinedAll, dfUserInfo_selected_columns, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjFiDMd-zwbv"
   },
   "source": [
    "## Position Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keJCoNLu7m__",
    "outputId": "d45b6516-87c4-41a2-e681-974fd26f7772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  userLocation userPosition speakerLocation speakerPosition  proximity\n",
      "0     Bed Room          Bed        Bed Room            Desk          1\n",
      "1    Rest Room          NaN        Bed Room            Desk          0\n",
      "2  Living Room          NaN        Bed Room            Desk          0\n",
      "3  Living Room          NaN        Bed Room            Desk          0\n",
      "4     Bed Room          Bed        Bed Room            Desk          1\n",
      "5     Bed Room          Bed        Bed Room            Desk          1\n",
      "6     Bed Room          Bed        Bed Room            Desk          1\n",
      "7     Bed Room         Desk        Bed Room            Desk          2\n",
      "8     Bed Room          Bed        Bed Room            Desk          1\n",
      "9     Bed Room          Bed        Bed Room            Desk          1\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate proximity between user and speaker\n",
    "def calculate_proximity(row):\n",
    "    # Return 0 if user and speaker are in different locations\n",
    "    if row['userLocation'] != row['speakerLocation']:\n",
    "        return 0\n",
    "    # If in the same locations\n",
    "    elif row['userPosition'] == row['speakerPosition']:\n",
    "        return 2  # Same position\n",
    "    else:\n",
    "        return 1  # Different positions (including missing position)\n",
    "\n",
    "# Apply proximity calculation to create a new 'proximity' column\n",
    "dfCombinedAll['proximity'] = dfCombinedAll.apply(calculate_proximity, axis=1)\n",
    "\n",
    "print(dfCombinedAll[['userLocation', 'userPosition', 'speakerLocation', 'speakerPosition', 'proximity']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hentOj4Gzjab"
   },
   "source": [
    "## Activity and Time Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wMot0sto22U8"
   },
   "outputs": [],
   "source": [
    "# Process activity columns for one-hot encoding\n",
    "activity_cols = ['activity1', 'activity2', 'activity3']\n",
    "df_activity = dfContextualFactor[activity_cols].copy()\n",
    "\n",
    "# Get unique activities across all activity columns, excluding NaN\n",
    "all_unique_activities = pd.unique(df_activity.values.ravel())\n",
    "all_unique_activities = [x for x in all_unique_activities if pd.notna(x)]\n",
    "\n",
    "# Create a DataFrame for one-hot encoding of activities\n",
    "dfActivity_one_hot_encoding = pd.DataFrame(0, index=df_activity.index, columns=['act_' + str(val) for val in all_unique_activities])\n",
    "\n",
    "# Perform one-hot encoding for each activity column\n",
    "for col in activity_cols:\n",
    "    for val in all_unique_activities:\n",
    "        dfActivity_one_hot_encoding['act_' + str(val)] |= (df_activity[col] == val).astype(int)\n",
    "\n",
    "# Concatenate one-hot encoded activity columns to dfCombinedAll\n",
    "dfActivity_one_hot_encoding\n",
    "dfCombinedAll = pd.concat([dfCombinedAll, dfActivity_one_hot_encoding], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "bt6nnuMOx00i",
    "outputId": "3faad9bb-8bbd-4417-e91a-516da4ff2251"
   },
   "outputs": [],
   "source": [
    "# Convert startTime to datetime and extract total minutes since midnight\n",
    "dfCombinedAll['startTime'] = pd.to_datetime(dfCombinedAll['startTime'], format='%H:%M:%S', errors='coerce')\n",
    "dfCombinedAll['minute'] = dfCombinedAll['startTime'].dt.hour * 60 + dfCombinedAll['startTime'].dt.minute\n",
    "\n",
    "# Map days of the week to numerical values (MON=0, TUE=1, ..., SUN=6)\n",
    "day_map = {'MON': 0, 'TUE': 1, 'WED': 2, 'THU': 3, 'FRI': 4, 'SAT': 5, 'SUN': 6}\n",
    "dfCombinedAll['dayOfWeek'] = dfCombinedAll['dayOfWeek'].map(day_map)\n",
    "\n",
    "# Bin minutes into 30-minute intervals for temporal analysis\n",
    "dfCombinedAll['minute_bin'] = (dfCombinedAll['minute'] // 30).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qFC4TOLGW-M",
    "outputId": "86d68c03-c6be-4c9f-d06f-ce3ac0ffe773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2830 entries, 0 to 2829\n",
      "Data columns (total 43 columns):\n",
      " #   Column                                    Non-Null Count  Dtype         \n",
      "---  ------                                    --------------  -----         \n",
      " 0   uid                                       2830 non-null   int64         \n",
      " 1   sid                                       2830 non-null   int64         \n",
      " 2   activity1                                 2830 non-null   object        \n",
      " 3   activity2                                 110 non-null    object        \n",
      " 4   activity3                                 3 non-null      object        \n",
      " 5   userLocation                              2830 non-null   object        \n",
      " 6   userPosition                              2343 non-null   object        \n",
      " 7   weekOfExperiment                          2830 non-null   int64         \n",
      " 8   dayOfWeek                                 2830 non-null   int64         \n",
      " 9   startTime                                 2830 non-null   datetime64[ns]\n",
      " 10  activityInquiry                           2826 non-null   object        \n",
      " 11  availabilityInquiry                       2088 non-null   object        \n",
      " 12  speechShadowing1                          1456 non-null   object        \n",
      " 13  speechShadowing2                          889 non-null    float64       \n",
      " 14  speechShadowing3                          788 non-null    float64       \n",
      " 15  speechShadowing4                          745 non-null    float64       \n",
      " 16  speechShadowing5                          714 non-null    float64       \n",
      " 17  continue-to-nextInquiry1                  1387 non-null   float64       \n",
      " 18  continue-to-nextInquiry2                  869 non-null    float64       \n",
      " 19  continue-to-nextInquiry3                  775 non-null    float64       \n",
      " 20  continue-to-nextInquiry4                  733 non-null    float64       \n",
      " 21  endTime                                   2830 non-null   float64       \n",
      " 22  endType                                   2830 non-null   object        \n",
      " 23  SHORT_INTERACTION_interruptibility        2830 non-null   object        \n",
      " 24  LONG_INTERACTION_interruptibility         2830 non-null   object        \n",
      " 25  homeType                                  2830 non-null   object        \n",
      " 26  speakerLocation                           2830 non-null   object        \n",
      " 27  speakerPosition                           2830 non-null   object        \n",
      " 28  proximity                                 2830 non-null   int64         \n",
      " 29  act_Taking a Nap / Sleeping               2830 non-null   int64         \n",
      " 30  act_Hygiene                               2830 non-null   int64         \n",
      " 31  act_Eating                                2830 non-null   int64         \n",
      " 32  act_Using Media                           2830 non-null   int64         \n",
      " 33  act_Social Interaction                    2830 non-null   int64         \n",
      " 34  act_Returning from Outside / Other Rooms  2830 non-null   int64         \n",
      " 35  act_Studying / Working                    2830 non-null   int64         \n",
      " 36  act_Others                                2830 non-null   int64         \n",
      " 37  act_House Chores                          2830 non-null   int64         \n",
      " 38  act_Self Caring                           2830 non-null   int64         \n",
      " 39  act_Visiting Outside / Other Rooms        2830 non-null   int64         \n",
      " 40  act_Resting                               2830 non-null   int64         \n",
      " 41  minute                                    2830 non-null   int32         \n",
      " 42  minute_bin                                2830 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(9), int32(1), int64(18), object(14)\n",
      "memory usage: 939.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dfCombinedAll.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgpGmTtdF7hJ"
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "TiDH8e3OI941",
    "outputId": "cc2acd18-c20f-4a8b-b810-b286f7a564a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2830 entries, 0 to 2829\n",
      "Data columns (total 22 columns):\n",
      " #   Column                                    Non-Null Count  Dtype\n",
      "---  ------                                    --------------  -----\n",
      " 0   uid                                       2830 non-null   int64\n",
      " 1   act_Taking a Nap / Sleeping               2830 non-null   int64\n",
      " 2   act_Hygiene                               2830 non-null   int64\n",
      " 3   act_Eating                                2830 non-null   int64\n",
      " 4   act_Using Media                           2830 non-null   int64\n",
      " 5   act_Social Interaction                    2830 non-null   int64\n",
      " 6   act_Returning from Outside / Other Rooms  2830 non-null   int64\n",
      " 7   act_Studying / Working                    2830 non-null   int64\n",
      " 8   act_Others                                2830 non-null   int64\n",
      " 9   act_House Chores                          2830 non-null   int64\n",
      " 10  act_Self Caring                           2830 non-null   int64\n",
      " 11  act_Visiting Outside / Other Rooms        2830 non-null   int64\n",
      " 12  act_Resting                               2830 non-null   int64\n",
      " 13  homeType                                  2830 non-null   int64\n",
      " 14  userLocation                              2830 non-null   int64\n",
      " 15  userPosition                              2830 non-null   int64\n",
      " 16  speakerLocation                           2830 non-null   int64\n",
      " 17  speakerPosition                           2830 non-null   int64\n",
      " 18  minute_bin                                2830 non-null   int64\n",
      " 19  dayOfWeek                                 2830 non-null   int64\n",
      " 20  SHORT_INTERACTION_interruptibility        2830 non-null   int64\n",
      " 21  LONG_INTERACTION_interruptibility         2830 non-null   int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 486.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>act_Taking a Nap / Sleeping</th>\n",
       "      <th>act_Hygiene</th>\n",
       "      <th>act_Eating</th>\n",
       "      <th>act_Using Media</th>\n",
       "      <th>act_Social Interaction</th>\n",
       "      <th>act_Returning from Outside / Other Rooms</th>\n",
       "      <th>act_Studying / Working</th>\n",
       "      <th>act_Others</th>\n",
       "      <th>act_House Chores</th>\n",
       "      <th>...</th>\n",
       "      <th>act_Resting</th>\n",
       "      <th>homeType</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userPosition</th>\n",
       "      <th>speakerLocation</th>\n",
       "      <th>speakerPosition</th>\n",
       "      <th>minute_bin</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>SHORT_INTERACTION_interruptibility</th>\n",
       "      <th>LONG_INTERACTION_interruptibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  act_Taking a Nap / Sleeping  act_Hygiene  act_Eating  act_Using Media  \\\n",
       "0    1                            1            0           0                0   \n",
       "1    1                            0            1           0                0   \n",
       "2    1                            0            0           1                0   \n",
       "3    1                            0            0           1                0   \n",
       "4    1                            1            0           0                0   \n",
       "\n",
       "   act_Social Interaction  act_Returning from Outside / Other Rooms  \\\n",
       "0                       0                                         0   \n",
       "1                       0                                         0   \n",
       "2                       0                                         0   \n",
       "3                       0                                         0   \n",
       "4                       0                                         0   \n",
       "\n",
       "   act_Studying / Working  act_Others  act_House Chores  ...  act_Resting  \\\n",
       "0                       0           0                 0  ...            0   \n",
       "1                       0           0                 0  ...            0   \n",
       "2                       0           0                 0  ...            0   \n",
       "3                       0           0                 0  ...            0   \n",
       "4                       0           0                 0  ...            0   \n",
       "\n",
       "   homeType  userLocation  userPosition  speakerLocation  speakerPosition  \\\n",
       "0         0             0             0                0                1   \n",
       "1         0             3             3                0                1   \n",
       "2         0             1             3                0                1   \n",
       "3         0             1             3                0                1   \n",
       "4         0             0             0                0                1   \n",
       "\n",
       "   minute_bin  dayOfWeek  SHORT_INTERACTION_interruptibility  \\\n",
       "0          12          0                                   0   \n",
       "1          15          0                                   1   \n",
       "2          12          1                                   1   \n",
       "3          13          1                                   1   \n",
       "4          18          1                                   0   \n",
       "\n",
       "   LONG_INTERACTION_interruptibility  \n",
       "0                                  1  \n",
       "1                                  1  \n",
       "2                                  1  \n",
       "3                                  1  \n",
       "4                                  1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for response prediction\n",
    "dfFeatresForResponse = dfCombinedAll[['uid',\n",
    "    'act_Taking a Nap / Sleeping','act_Hygiene','act_Eating','act_Using Media','act_Social Interaction',\n",
    "    'act_Returning from Outside / Other Rooms','act_Studying / Working','act_Others','act_House Chores',\n",
    "    'act_Self Caring','act_Visiting Outside / Other Rooms','act_Resting',\n",
    "    'homeType','userLocation','userPosition','speakerLocation','speakerPosition',\n",
    "    'minute_bin','dayOfWeek','SHORT_INTERACTION_interruptibility','LONG_INTERACTION_interruptibility']].copy()\n",
    "\n",
    "# Encode categorical columns using LabelEncoder\n",
    "categorical_columns = ['homeType', 'userLocation', 'userPosition', 'speakerLocation', 'speakerPosition', 'minute_bin','SHORT_INTERACTION_interruptibility','LONG_INTERACTION_interruptibility']\n",
    "label_encoders = defaultdict(LabelEncoder)\n",
    "\n",
    "# Apply label encoding to each categorical column\n",
    "for col in categorical_columns:\n",
    "    dfFeatresForResponse[col] = label_encoders[col].fit_transform(dfFeatresForResponse[col])\n",
    "\n",
    "# Create a copy of the encoded data for further processing\n",
    "encoded_data = dfFeatresForResponse.copy()\n",
    "\n",
    "\n",
    "encoded_data.info()\n",
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMRZiUdWthAG"
   },
   "source": [
    "## Label: SHORT_INTERACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7R3RWMV4n8-",
    "outputId": "77f86bd9-b1fc-48ae-fb86-fc413af67e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORT_INTERACTION_interruptibility\n",
      "0    2088\n",
      "1     742\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Label distribution before balancing\n",
    "print(encoded_data['SHORT_INTERACTION_interruptibility'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsOz6lgfpGjB"
   },
   "source": [
    "### Model Building and LOSO CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrKX-wJlMMp9",
    "outputId": "3d573ad8-f06e-4f47-f442-9636a9a7325e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare features (X) and target variables (y) for SHORT_INTERACTION\n",
    "X = encoded_data.drop(columns=['SHORT_INTERACTION_interruptibility', 'LONG_INTERACTION_interruptibility', 'uid'], axis=1) # Drop target and unrelated columns\n",
    "y = encoded_data['SHORT_INTERACTION_interruptibility'] # Target variable\n",
    "groups = encoded_data['uid'] # Group by user ID for Leave-One-Group-Out CV\n",
    "\n",
    "# Initialize Leave-One-Group-Out cross-validator\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize SMOTE for oversampling to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Define models to evaluate\n",
    "models1 = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, verbose=0),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, verbosity=0, use_label_encoder=False),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, verbose=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, depth=5, learning_rate=0.1, loss_function='Logloss', cat_features=[0], random_seed=42, verbose=0),\n",
    "    'SVM': SVC(random_state=42, verbose=False),\n",
    "    'Dummy': DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "}\n",
    "\n",
    "results1_logo = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model1 in models1.items():\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Loop over each fold in Leave-One-Group-Out cross-validation\n",
    "    for i, (train_index, test_index) in enumerate(logo.split(X, y, groups)):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Apply SMOTE to the training data to balance class distribution\n",
    "        X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train the model on the oversampled training data\n",
    "        model1.fit(X_train_oversampled, y_train_oversampled.to_numpy())\n",
    "\n",
    "        # Predict the target on the test data\n",
    "        y_pred = model1.predict(X_test)\n",
    "\n",
    "        # Evaluate the prediction\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "    # Compute average accuracy and F1-score across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    results1_logo[model_name] = {\n",
    "        'Average Accuracy': avg_accuracy,\n",
    "        'Average F1-Score (macro)': avg_f1_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YD9tgjzEppKh"
   },
   "source": [
    "### K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ITwfO-xNYwH",
    "outputId": "3a817c09-01fb-4962-abe4-1c186db6e9ec",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize 5-fold cross-validator\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "results1_kfold = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model1 in models1.items():\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Loop over each fold in 5-fold cross-validation\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Apply SMOTE to the training data to balance class distribution\n",
    "        X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train the model on the oversampled training data\n",
    "        model1.fit(X_train_oversampled, y_train_oversampled.to_numpy())\n",
    "\n",
    "        # Predict the target on the test data\n",
    "        y_pred = model1.predict(X_test)\n",
    "\n",
    "        # Evaluate the prediction\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Compute average accuracy and F1-score across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    results1_kfold[model_name] = {\n",
    "        'Average Accuracy': avg_accuracy,\n",
    "        'Average F1-Score (macro)': avg_f1_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCsjDX20tfim"
   },
   "source": [
    "## Label: LONG_INTERACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZVe51NM4i6P",
    "outputId": "508395cd-a696-4176-db4c-33caa2236916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG_INTERACTION_interruptibility\n",
      "1    1443\n",
      "0    1387\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Label distribution before balancing\n",
    "print(encoded_data['LONG_INTERACTION_interruptibility'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SkfxAFQqEwa"
   },
   "source": [
    "### Model building and LOSO CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSZBAAdESGEd",
    "outputId": "390ec19e-29d5-4b39-eaa5-7ca6293420bd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare features (X) and target variable (y) for predicting LONG_INTERACTION\n",
    "X = encoded_data.drop(columns=['LONG_INTERACTION_interruptibility', 'SHORT_INTERACTION_interruptibility','uid'], axis=1)\n",
    "y = encoded_data['LONG_INTERACTION_interruptibility']\n",
    "groups = encoded_data['uid']\n",
    "\n",
    "# Initialize Leave-One-Group-Out cross-validator\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize SMOTE for oversampling to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Define models to evaluate\n",
    "models2 = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, verbose=0),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, verbosity=0, use_label_encoder=False),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, verbose=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, depth=5, learning_rate=0.1, loss_function='Logloss', cat_features=[0], random_seed=42, verbose=0),\n",
    "    'SVM': SVC(random_state=42, verbose=False),\n",
    "    'Dummy': DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "}\n",
    "\n",
    "results2_logo = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model2 in models2.items():\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Loop over each fold in Leave-One-Group-Out cross-validation\n",
    "    for i, (train_index, test_index) in enumerate(logo.split(X, y, groups)):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Apply SMOTE to the training data to balance class distribution\n",
    "        X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train the model on the oversampled training data\n",
    "        model2.fit(X_train_oversampled, y_train_oversampled.to_numpy())\n",
    "\n",
    "        # Predict the target on the test data\n",
    "        y_pred = model2.predict(X_test)\n",
    "\n",
    "        # Evaluate the prediction\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Compute average accuracy and F1-score across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    results2_logo[model_name] = {\n",
    "        'Average Accuracy': avg_accuracy,\n",
    "        'Average F1-Score (macro)': avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3smYpTiAqqQh"
   },
   "source": [
    "### K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah_QrD67SnHN",
    "outputId": "8cf8cc9f-d0c2-4934-e730-7874ecb6cb97",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize 5-fold cross-validator\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "results2_kfold = {}\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model2 in models2.items():\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Loop over each fold in 5-fold cross-validation\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Apply SMOTE to the training data to balance class distribution\n",
    "        X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Train the model on the oversampled training data\n",
    "        model2.fit(X_train_oversampled, y_train_oversampled.to_numpy())\n",
    "\n",
    "        # Predict the target on the test data\n",
    "        y_pred = model2.predict(X_test)\n",
    "\n",
    "        # Evaluate the prediction\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Compute average accuracy and F1-score across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    results2_kfold[model_name] = {\n",
    "        'Average Accuracy': avg_accuracy,\n",
    "        'Average F1-Score (macro)': avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning model performance\n",
      "╒═══════════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╕\n",
      "│ Model             │       LOSO CV │       LOSO CV │       LOSO CV │       LOSO CV │     5-fold CV │     5-fold CV │     5-fold CV │     5-fold CV │\n",
      "│                   │         Short │         Short │          Long │          Long │         Short │         Short │          Long │          Long │\n",
      "│                   │   Interaction │   Interaction │   Interaction │   Interaction │   Interaction │   Interaction │   Interaction │   Interaction │\n",
      "│                   │      Accuracy │            F1 │      Accuracy │            F1 │      Accuracy │            F1 │      Accuracy │            F1 │\n",
      "╞═══════════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╡\n",
      "│ Random Forest     │         0.828 │         0.746 │         0.686 │         0.636 │         0.821 │         0.786 │         0.673 │         0.670 │\n",
      "├───────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│ Gradient Boosting │         0.810 │         0.715 │         0.675 │         0.609 │         0.811 │         0.769 │         0.671 │         0.667 │\n",
      "├───────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│ XGBoost           │         0.810 │         0.715 │         0.684 │         0.614 │         0.806 │         0.764 │         0.681 │         0.676 │\n",
      "├───────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│ LightGBM          │         0.812 │         0.719 │         0.689 │         0.621 │         0.807 │         0.765 │         0.684 │         0.679 │\n",
      "├───────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│ CatBoost          │         0.817 │         0.734 │         0.698 │         0.624 │         0.806 │         0.768 │         0.670 │         0.665 │\n",
      "├───────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│ SVM               │         0.789 │         0.700 │         0.668 │         0.621 │         0.767 │         0.725 │         0.619 │         0.618 │\n",
      "├───────────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n",
      "│ Dummy             │         0.493 │         0.448 │         0.512 │         0.479 │         0.515 │         0.476 │         0.504 │         0.503 │\n",
      "╘═══════════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Models list\n",
    "models = [\n",
    "    'Random Forest', 'Gradient Boosting', 'XGBoost',\n",
    "    'LightGBM', 'CatBoost', 'SVM', 'Dummy'\n",
    "]\n",
    "\n",
    "# Prepare table data\n",
    "table_data = []\n",
    "for model in models:\n",
    "    row = [model]\n",
    "    \n",
    "    # Shell 1: SHORT_INTERACTION, Leave-One-Group-Out\n",
    "    row.append(results1_logo.get(model, {}).get('Average Accuracy', 0.0))\n",
    "    row.append(results1_logo.get(model, {}).get('Average F1-Score (macro)', 0.0))\n",
    "    \n",
    "    # Shell 3: LONG_INTERACTION, Leave-One-Group-Out\n",
    "    row.append(results2_logo.get(model, {}).get('Average Accuracy', 0.0))\n",
    "    row.append(results2_logo.get(model, {}).get('Average F1-Score (macro)', 0.0))\n",
    "\n",
    "    # Shell 2: SHORT_INTERACTION, 5-fold\n",
    "    row.append(results1_kfold.get(model, {}).get('Average Accuracy', 0.0))\n",
    "    row.append(results1_kfold.get(model, {}).get('Average F1-Score (macro)', 0.0))\n",
    "    \n",
    "    # Shell 4: LONG_INTERACTION, 5-fold\n",
    "    row.append(results2_kfold.get(model, {}).get('Average Accuracy', 0.0))\n",
    "    row.append(results2_kfold.get(model, {}).get('Average F1-Score (macro)', 0.0))\n",
    "    \n",
    "    table_data.append(row)\n",
    "\n",
    "# Define headers\n",
    "headers = [\n",
    "    'Model',\n",
    "    'LOSO CV\\nShort\\nInteraction\\nAccuracy', 'LOSO CV\\nShort\\nInteraction\\nF1',\n",
    "    'LOSO CV\\nLong\\nInteraction\\nAccuracy', 'LOSO CV\\nLong\\nInteraction\\nF1',\n",
    "    '5-fold CV\\nShort\\nInteraction\\nAccuracy', '5-fold CV\\nShort\\nInteraction\\nF1',\n",
    "    '5-fold CV\\nLong\\nInteraction\\nAccuracy', '5-fold CV\\nLong\\nInteraction\\nF1'\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(\"Machine learning model performance\")\n",
    "print(tabulate(table_data, headers=headers, tablefmt='fancy_grid', floatfmt='.3f', numalign=\"decimal\"))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
